{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csc_matrix\n",
    "from scipy.sparse.linalg import svds as SVDS\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from string import punctuation\n",
    "import unidecode\n",
    "import os\n",
    "\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('machado')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('rslp')\n",
    "\n",
    "# %pip install spacy\n",
    "# %spacy download pt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "pln = spacy.load('pt_core_news_sm')\n",
    "\n",
    "\n",
    "def pre_processamento(texto):\n",
    "    texto = texto.lower()\n",
    "    documento = pln(texto)\n",
    "    lista = []\n",
    "    # tratamento de stopWords e pontuações\n",
    "    pontuacao_stopwords = nltk.corpus.stopwords.words(\n",
    "        \"portuguese\") + list(punctuation)\n",
    "    # tratamento de stopwords sem acento.\n",
    "    stopwords_sem_acento = [unidecode.unidecode(\n",
    "        texto) for texto in pontuacao_stopwords]\n",
    "    # Tokenização por pontuação\n",
    "    for token in documento:\n",
    "        if token.lower_ not in stopwords_sem_acento:\n",
    "            lista.append(token.lemma_)\n",
    "    return lista\n",
    "\n",
    "\n",
    "def ler_arquivo_emocao(emocao, path='emocoes'):\n",
    "    with open(f'{path}/{emocao}', 'r') as h:\n",
    "        palavras = h.readlines()\n",
    "        for i, palavra in enumerate(palavras):\n",
    "            palavra = palavra.replace('\\n', '').lower().strip()\n",
    "            palavras[i] = ''.join(palavra)\n",
    "            # words[i] = [w.lemma_ for w in NLP(word, disable=['parser'])][0]\n",
    "    return sorted(list(set(palavras)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "emocoes = {\n",
    "    'ALEGRIA': ler_arquivo_emocao('alegria'),\n",
    "    'DESGOSTO': ler_arquivo_emocao('desgosto'),\n",
    "    'MEDO': ler_arquivo_emocao('medo'),\n",
    "    'RAIVA': ler_arquivo_emocao('raiva'),\n",
    "    'SURPRESA': ler_arquivo_emocao('surpresa'),\n",
    "    'TRISTEZA': ler_arquivo_emocao('tristeza'),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimentos = {\n",
    "    'POSITIVO': ler_arquivo_emocao('positivo'),\n",
    "    'NEGATIVO': ler_arquivo_emocao('negativo'),\n",
    "    'NEUTRO': ler_arquivo_emocao('neutro'),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "machado_contos_data = [\n",
    "    {\n",
    "        'data': '1870',\n",
    "        'nome': 'CONTOS FLUMINENSES',\n",
    "        'caminho_livro_txt': 'obras\\\\conto\\\\1870_contosFluminenses.txt',\n",
    "        'caminho_contos_txt': 'CONTOS\\CONTOS_FLUMINENSES',\n",
    "\n",
    "\n",
    "    },  {\n",
    "        'data': '1873',\n",
    "        'nome': 'HISTÓRIAS DA MEIA-NOITE',\n",
    "        'caminho_livro_txt': 'obras\\\\conto\\\\1873_historiasMeiaNoite.txt',\n",
    "        'caminho_contos_txt': 'CONTOS\\HISTORIAS_DA_MEIA_NOITE',\n",
    "\n",
    "\n",
    "    },  {\n",
    "        'data': '1882',\n",
    "        'nome': 'PAPÉIS AVULSOS',\n",
    "        'caminho_livro_txt': 'obras\\\\conto\\\\1882_papeisAvulsos.txt',\n",
    "        'caminho_contos_txt': 'CONTOS\\PAPEIS_AVULSOS',\n",
    "\n",
    "\n",
    "    },  {\n",
    "        'data': '1884',\n",
    "        'nome': 'HISTÓRIAS SEM DATA',\n",
    "        'caminho_livro_txt': 'obras\\\\conto\\\\1884_historiasSemData.txt',\n",
    "        'caminho_contos_txt': 'CONTOS\\HISTORIAS_SEM_DATA',\n",
    "\n",
    "\n",
    "    },  {\n",
    "        'data': '1896',\n",
    "        'nome': 'VÁRIAS HISTÓRIAS',\n",
    "        'caminho_livro_txt': 'obras\\\\conto\\\\1896_variasHistorias.txt',\n",
    "        'caminho_contos_txt': 'CONTOS\\VARIAS_HISTORIAS',\n",
    "\n",
    "\n",
    "    },  {\n",
    "        'data': '1899',\n",
    "        'nome': 'PÁGINAS RECOLHIDAS',\n",
    "        'caminho_livro_txt': 'obras\\\\conto\\\\1899_paginasRecolhidas.txt',\n",
    "        'caminho_contos_txt': 'CONTOS\\PAGINAS_RECOLHIDAS',\n",
    "\n",
    "\n",
    "    },  {\n",
    "        'data': '1906',\n",
    "        'nome': 'RELÍQUIAS DE CASA VELHA',\n",
    "        'caminho_livro_txt': 'obras\\\\conto\\\\1906_reliquias.txt',\n",
    "        'caminho_contos_txt': 'CONTOS\\RELIQUIAS_DE_CASA_VELHA',\n",
    "\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consultar_arquivos(item):\n",
    "    dic_contos = {}\n",
    "    path = item.get('caminho_contos_txt')\n",
    "    for file in os.listdir(item.get('caminho_contos_txt')):\n",
    "        if file.endswith(\".txt\"):\n",
    "            file_path = f\"{path}\\{file}\"\n",
    "            with open(file_path, 'r', encoding=\"UTF-8\") as f:\n",
    "                dic_contos[file] = f.read()\n",
    "    item['contos'] = dic_contos\n",
    "\n",
    "\n",
    "for livro in machado_contos_data:\n",
    "    with open(livro.get('caminho_livro_txt'), 'r', encoding=\"UTF-8\") as f:\n",
    "        livro['livro'] = f.read()\n",
    "    consultar_arquivos(livro)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcula_pesos_sentimentos(rank,  sentimentos, pesos,  U):\n",
    "\n",
    "    WV = np.zeros((len(sentimentos.keys()), rank))\n",
    "    for k, values in enumerate(sentimentos.values()):\n",
    "        for value in values:\n",
    "            pattern = re.compile(r'\\b({})\\b'.format(value))\n",
    "            indexes = [e for e, inx in enumerate(\n",
    "                pesos.index.values) if pattern.search(inx)]\n",
    "            if len(indexes) > 0:\n",
    "                WV[k, :] += [U[index] for index in indexes][0]\n",
    "    return WV / rank\n",
    "\n",
    "\n",
    "def normalizar(x,  a,  b):\n",
    "    return (2 * b) * (x - np.min(x)) / np.ptp(x) + a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calcula_pesos_contos(texto, emocoes):\n",
    "    # utlizando o Tf-Idf vectorizer, criando dataframe e definindo valores padrao.\n",
    "    _vectorize = TfidfVectorizer()\n",
    "    X = _vectorize.fit_transform(texto)\n",
    "    pesos = pd.DataFrame(X.T.toarray(), index=_vectorize.get_feature_names())\n",
    "    rank = 100\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    # calculo SVD\n",
    "    X2 = csc_matrix(pesos, dtype=np.float32)\n",
    "    k = min(X2.shape)\n",
    "    k = rank if k > rank else k - 1\n",
    "    U, S, V = SVDS(X2, k=k)\n",
    "    rank = max(min(U.shape), min(V.shape))\n",
    "\n",
    "   # Vamos processar apenas as palavras que refletem sentimentos que realmente existem em nosso corpus\n",
    "    lista_palavras = [w for i, w in enumerate(pesos.index)]\n",
    "    for key, values in emocoes.items():\n",
    "        emocoes[key] = [value for value in values if value in lista_palavras]\n",
    "        \n",
    "    WV = calcula_pesos_sentimentos(rank, emocoes, pesos, U)\n",
    "\n",
    "    qttd_contos = len(texto)\n",
    "    qttd_emocoes = len(emocoes.keys())\n",
    "    dtframe = np.ones((qttd_contos + 2, qttd_emocoes))\n",
    "    dtframe[-1, :] = np.tile([-1], qttd_emocoes)\n",
    "\n",
    "    for k in range(qttd_emocoes):\n",
    "        for i in range(qttd_contos):\n",
    "            dtframe[i][k] = cosine_similarity([WV[k]], [V.T[i, :]])\n",
    "            mmax, mmin = np.max(dtframe[i]), np.min(dtframe[i])\n",
    "            if abs(mmin) > mmax:\n",
    "                dtframe[i] = -dtframe[i]\n",
    "    return np.round(normalizar(dtframe, 1, 100)[:-2], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotar_grafico_area(pesos, categories, nome, titulo):\n",
    "    categories = [*categories, categories[0]]\n",
    "\n",
    "    label_loc = np.linspace(start=0, stop=2 * np.pi, num=len(categories))\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.subplot(polar=True)\n",
    "\n",
    "    restaurant_1 = pesos\n",
    "    restaurant_1 = [*restaurant_1, restaurant_1[0]]\n",
    "    plt.plot(label_loc, restaurant_1)\n",
    "    plt.title(nome, size=20, y=1.05)\n",
    "    lines, labels = plt.thetagrids(np.degrees(label_loc), labels=categories)\n",
    "    plt.legend()\n",
    "    plt.savefig(\"graficos/\"+titulo+\"/area/\"+nome + '.jpeg', format='jpeg')\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotar_grafico_ponto(peso_contos_livro, nome_contos, titulo):\n",
    "    alegria = []\n",
    "    desgosto = []\n",
    "    medo = []\n",
    "    raiva = []\n",
    "    surpresa = []\n",
    "    tristeza = []\n",
    "    y_pos = np.arange(len(nome_contos))\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    for peso in peso_contos_livro:\n",
    "        alegria.append(peso[0])\n",
    "        desgosto.append(peso[1])\n",
    "        medo.append(peso[2])\n",
    "        raiva.append(peso[3])\n",
    "        surpresa.append(peso[4])\n",
    "        tristeza.append(peso[5])\n",
    "\n",
    "    plt.xticks(y_pos, nome_contos, rotation=90)\n",
    "\n",
    "    # Thus we have to give more margin:\n",
    "    plt.subplots_adjust(bottom=0.4)\n",
    "    plt.plot(alegria, linestyle=\"-\", marker=\"o\", label=\"alegria\")\n",
    "    plt.plot(desgosto, linestyle=\"-\", marker=\"o\", label=\"desgosto\")\n",
    "    plt.plot(medo, linestyle=\"-\", marker=\"o\", label=\"medo\")\n",
    "    plt.plot(raiva, linestyle=\"-\", marker=\"o\", label=\"raiva\")\n",
    "    plt.plot(tristeza, linestyle=\"-\", marker=\"o\", label=\"tristeza\")\n",
    "    plt.plot(surpresa, linestyle=\"-\", marker=\"o\", label=\"surpresa\")\n",
    "    plt.title(titulo, size=20, y=1.05)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.savefig(\"graficos/livros/pontos/\" + titulo + '.jpeg', format='jpeg')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotar_grafico_barra(peso, nome,titulo):\n",
    "\n",
    "    height = peso\n",
    "    bars = list(emocoes.keys())\n",
    "    y_pos = np.arange(len(bars))\n",
    "\n",
    "    # Create bars\n",
    "    plt.bar(y_pos, height, color=['yellow', 'red', 'green', 'orange','blue', 'cyan'])\n",
    "    \n",
    "    plt.title(nome, size=20, y=1.05)\n",
    "\n",
    "    # Create names on the x-axis\n",
    "    plt.xticks(y_pos, bars)\n",
    "    plt.savefig(\"graficos/\"+titulo+\"/barra/\"+nome + '.jpeg', format='jpeg')\n",
    "\n",
    "    # Show graphic\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotar_grafico_area_contos_livro(categories, pesos, nomes, titulo):\n",
    "    categories = [*categories, categories[0]]\n",
    "\n",
    "    label_loc = np.linspace(start=0, stop=2 * np.pi, num=len(categories))\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.subplot(polar=True)\n",
    "    for index in range(len(pesos)):\n",
    "        restaurant_1 = pesos[index]\n",
    "        restaurant_1 = [*restaurant_1, restaurant_1[0]]\n",
    "        plt.plot(label_loc, restaurant_1, label=nomes[index])\n",
    "    plt.title(titulo, size=20, y=1.05)\n",
    "    lines, labels = plt.thetagrids(np.degrees(label_loc), labels=categories)\n",
    "    plt.legend()\n",
    "    plt.savefig(\"graficos/livros/area/\"+titulo + '.jpeg', format='jpeg')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "todos_livros = []\n",
    "nome_todos_livros = []\n",
    "for item in machado_contos_data:\n",
    "    nome_todos_livros.append(item.get('nome'))\n",
    "    todos_livros.append(item.get('livro'))\n",
    "peso_livros = calcula_pesos_contos(todos_livros, emocoes)\n",
    "plotar_grafico_area_contos_livro(list(\n",
    "    emocoes.keys()),  peso_livros, nome_todos_livros, 'Livros de Contos de Machado de Assis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n"
     ]
    }
   ],
   "source": [
    "for index in range(len(peso_livros)):\n",
    "    peso_do_livro = peso_livros[index]\n",
    "    nome = nome_todos_livros[index]\n",
    "    plotar_grafico_area(peso_do_livro, list(emocoes.keys()), nome, nome)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n"
     ]
    }
   ],
   "source": [
    "todos_contos = []\n",
    "nome_contos = []\n",
    "peso_livros_contos = []\n",
    "nome_livros_contos = []\n",
    "for item in machado_contos_data:\n",
    "    contos = item.get('contos')\n",
    "    contos_livro = []\n",
    "    nome_contos_livro = []\n",
    "    for conto in contos:\n",
    "        contos_livro.append(contos.get(conto))\n",
    "        nome_contos_livro.append(conto)\n",
    "        todos_contos.append(contos.get(conto))\n",
    "        nome_contos.append(conto)\n",
    "    peso_contos_livro = calcula_pesos_contos(contos_livro, emocoes)\n",
    "    peso_livros_contos.append(peso_contos_livro)\n",
    "    nome_livros_contos.append(nome_contos_livro)\n",
    "    plotar_grafico_area_contos_livro(list(emocoes.keys()),  peso_contos_livro, nome_contos_livro,item.get('nome'))\n",
    "    plotar_grafico_ponto(peso_contos_livro, nome_contos_livro, item.get('nome'))\n",
    "    for index in range(len(peso_contos_livro)):\n",
    "        peso = peso_contos_livro[index]\n",
    "        nome = nome_contos_livro[index]\n",
    "        plotar_grafico_area(peso, list(emocoes.keys()), nome, item.get('nome'))\n",
    "        plotar_grafico_barra(peso, nome, item.get('nome'))\n",
    "\n",
    "\n",
    "peso_contos = calcula_pesos_contos(todos_contos, emocoes)\n",
    "plotar_grafico_ponto(peso_contos, nome_contos, 'Contos de Machado de Assis')\n",
    "plotar_grafico_area_contos_livro( list(emocoes.keys()),  peso_contos, nome_contos,'Contos de Machado de Assis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "antes = []\n",
    "depois = []\n",
    "antes  = nome_livros_contos[1]\n",
    "depois = nome_livros_contos[2]\n",
    "peso_antes = peso_livros_contos[1]\n",
    "peso_depois = peso_livros_contos[2]\n",
    "\n",
    "for a in depois:\n",
    "    antes.append(a);\n",
    "\n",
    "alegria = []\n",
    "desgosto = []\n",
    "medo = []\n",
    "raiva = []\n",
    "surpresa = []\n",
    "tristeza = []\n",
    "y_pos = np.arange(len(antes))\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for peso in peso_antes:\n",
    "    alegria.append(peso[0])\n",
    "    desgosto.append(peso[1])\n",
    "    medo.append(peso[2])\n",
    "    raiva.append(peso[3])\n",
    "    surpresa.append(peso[4])\n",
    "    tristeza.append(peso[5])\n",
    "\n",
    "for peso in peso_depois:\n",
    "    alegria.append(peso[0])\n",
    "    desgosto.append(peso[1])\n",
    "    medo.append(peso[2])\n",
    "    raiva.append(peso[3])\n",
    "    surpresa.append(peso[4])\n",
    "    tristeza.append(peso[5])\n",
    "\n",
    "plt.xticks(y_pos, antes, rotation=90)\n",
    "\n",
    "# Thus we have to give more margin:\n",
    "plt.subplots_adjust(bottom=0.4)\n",
    "plt.plot(alegria, linestyle=\"-\", marker=\"o\", label=\"alegria\")\n",
    "plt.plot(desgosto, linestyle=\"-\", marker=\"o\", label=\"desgosto\")\n",
    "plt.plot(medo, linestyle=\"-\", marker=\"o\", label=\"medo\")\n",
    "plt.plot(raiva, linestyle=\"-\", marker=\"o\", label=\"raiva\")\n",
    "plt.plot(tristeza, linestyle=\"-\", marker=\"o\", label=\"tristeza\")\n",
    "plt.plot(surpresa, linestyle=\"-\", marker=\"o\", label=\"surpresa\")\n",
    "plt.title(\"Mudanca na ruptura\", size=20, y=1.05)\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig(\"graficos/livros/pontos/\" + \"Ruptura\" + '.jpeg', format='jpeg')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c4f92193806e2908606a5f23edd55a5282f2f433b73b1c504507f9256ed9f0b4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
